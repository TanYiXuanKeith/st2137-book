---
title: "ANalysis Of VAriance (ANOVA)"
format: 
  beamer:
    aspectratio: 169
    theme: Boadilla
    navigation: empty
    colortheme: lily
    footer: "ST2137-2420"

execute:
  echo: true
---

```{r}
#| echo: false
library(knitr)
library(reticulate)
venv_paths <- read.csv("../venv_paths.csv")
id <- match(Sys.info()["nodename"], venv_paths$nodename)
use_virtualenv(venv_paths$path[id])
```

## Motivation {.smaller}

* Instead of just 2 groups, we frequently have to compare means from more than 
  2 groups. 
* For this purpose, we introduce the *one-way analysis of variance* (ANOVA), 
  * it generalises the $t$-test methodology to more than 2 groups. 
  * Hypothesis tests here require the assumption of Normality. 
* Kruskal-Wallis test is the non-parametric version

## Effect of Antibiotics

* 36 heifers were randomly assigned into six groups. 
* Antibiotics of different types were added to the feed for heifers in five of the 
  groups. 
* The remaining group served as a control group. 
* For each heifer, a bag of dung was dug into the soil, and after 8 weeks the amount of 
  organic material was measured for each bag.

## Effect of Antibiotics

```{r heifer-plot}
#| fig-align: center
#| echo: false
#| out-width: 60%
library(lattice)
heifers <- read.csv("data/antibio.csv")
u_levels <- sort(unique(heifers$type))
heifers$type <- factor(heifers$type, levels=u_levels[c(2, 1, 3, 4, 5, 6)])
bwplot(org ~ as.factor(type), data=heifers, 
       main="Organic Weight after 8 weeks")
```

## Antibiotics Example {.smaller}

* Compared to the control group, it does appear that the median organic weight of
  the dung from the other heifer groups is higher.
* Observe that the Spiramycin group only yielded 4 readings instead of 6. 

```{r heifer-summary}
#| echo: FALSE
aggregate(org ~ type, heifers, function(x) c(mean = mean(x),  
                                             sd = sd(x),
                                             count=as.integer(length(x))))
```

## Antibiotics Example {.smaller}

1. Is there any significant difference, at 5% level, between the mean decomposition
   level of the groups?
2. At 5% level, is the mean level for Enrofloxacin different from the control group?
3. Pharmacologically speaking, Ivermectin and Fenbendazole are similar to each
   other. Let us call this sub-group (A). They work differently than Enrofloxacin.
   At 5% level, is there a significant difference between the mean from sub-group 
   A and Enrofloxacin?

## Formal Set-up Distributions {.smaller}

* Suppose there are $k$ groups with $n_i$ observations in the $i$-th group. 
* The $j$-th observation in the $i$-th group will be denoted by $Y_{ij}$.

\begin{equation}
Y_{ij}  = \mu + \alpha_i + e_{ij},\; i=1,\ldots,k,\; j=1,\ldots,n_i
\end{equation}

* $\mu$ is a constant, representing the underlying mean of all groups taken together.
* $\alpha_i$ is a constant specific to the $i$-th group.
* $e_{ij}$ represents random error about the mean $\mu + \alpha_i$ for an individual 
  observation from the $i$-th group.

## Formal Set-up Distributions {.smaller}

* Assume that the $e_{ij}$ are i.i.d from a Normal distribution with mean 0 and
  variance $\sigma^2$. 

$$
Y_{ij} \sim N(\mu + \alpha_i,\; \sigma^2)
$$ {#eq-yij}

* It is not possible to estimate both $\mu$ and all the $k$ different $\alpha_i$'s.
* Identifiability constraints:
    1. Setting $\sum_{i=1}^k \alpha_i = 0$, or
    2. Setting $\alpha_1= 0$.

## Formal Set-up Notation {.smaller}

* Denote the mean for the $i$-th group as $\overline{Y_i}$, and 
* The overall mean of all observations as $\overline{\overline{Y}}$. 
* We can then write the deviation of an individual observation from the overall mean as:

$$
Y_{ij} - \overline{\overline{Y}} = \underbrace{(Y_{ij} - \overline{Y_i})}_{\text{within}} + 
\underbrace{(\overline{Y_i} - \overline{\overline{Y}})}_{\text{between}}
$$ {#eq-y-dev}

## Formal Set-up Notation {.smaller}

If we square both sides of @eq-y-dev and sum over all observations, we arrive
at:

$$
\sum_{i=1}^k \sum_{j=1}^{n_i} \left( Y_{ij} - \overline{\overline{Y}} \right)^2 =
\sum_{i=1}^k \sum_{j=1}^{n_i} \left( Y_{ij} - \overline{Y_i} \right)^2 + 
\sum_{i=1}^k \sum_{j=1}^{n_i} \left( \overline{Y_i} - 
                                     \overline{\overline{Y}} \right)^2 
$$

## Mean Squares {.smaller}


1. The Between Mean Square:
$$
MS_B = \frac{SS_B}{k-1}
$$
2. The Within Mean Square:
$$
MS_W = \frac{SS_W}{n - k}
$$

* The mean squares are estimates of the variability between and within groups. 
* The ratio of these quantities is the test statistic.

## $F$-Test in One-Way ANOVA {.smaller}

The null and alternative hypotheses are:

\begin{eqnarray*}
H_0 &:& \alpha_i = 0 \text{ for all } i \\
H_1 &:& \alpha_i \ne 0 \text{ for at least one } i
\end{eqnarray*}

The test statistic is given by 
$$
F = \frac{MS_B}{MS_W}
$$

Under $H_0$, the statistic $F$ follows an $F$ distribution with $k-1$ and $n-k$
degrees of freedom.

## Assumptions {.smaller}

These are the assumptions that will need to be validated.

1. The observations are independent of each other. 
2. The errors are Normally distributed. Residuals can be calculated as follows:
$$
Y_{ij} - \overline{Y_i}
$$
   The distribution of these residuals should be checked for Normality.
3. The variance within each group is the same. In ANOVA, the $MS_W$ is a pooled 
   estimate (across the groups) that is used; in order for this to be valid,
   the variance within each group should be identical. As in the 2-sample situation,
   we shall avoid separate hypotheses tests and proceed with the rule-of-thumb
   that if the ratio of the largest to smallest standard deviation is less than
   2, we can proceed with the analysis.

## F-test for Antibiotics data  {.smaller}

### R code 

```{r r-f-test}
#R 
heifers <- read.csv("data/antibio.csv")
u_levels <- sort(unique(heifers$type))
heifers$type <- factor(heifers$type, 
                       levels=u_levels[c(2, 1, 3, 4, 5, 6)])
heifers_lm <- lm(org ~ type, data=heifers)
anova(heifers_lm)
```

## F-test for Antibiotics data  {.smaller}

### Python code 

```{python py-f-test-a}
#| echo: false
#Python
import pandas as pd
import numpy as np
from scipy import stats
import statsmodels.api as sm
from statsmodels.formula.api import ols
import matplotlib.pyplot as plt
```

```{python py-f-test-b}
heifers = pd.read_csv("data/antibio.csv")
heifers_lm = ols('org ~ type', data=heifers).fit()
anova_tab = sm.stats.anova_lm(heifers_lm, type=3,)
```
```{python py-f-test-c}
#| echo: false
print(anova_tab)
```

## F-test for Antibiotics data  {.smaller}

### SAS output

![](../figs/sas_anova_f_test.png){width="70%" fig-align="center"}

At the 5% significance level, we reject the null hypothesis to conclude that the
group means are significantly different from one another.

## Parameters for Antibiotics data  {.smaller}

### R code 

```{r r-coef}
# R
coef(heifers_lm)
```

## Parameters for Antibiotics data  {.smaller}

### Python code 

```{python py-coef}
# Python
heifers_lm.summary()
```

## Assumptions for Antibiotics Data {.smaller}

### R code 

```{r r-normality}
#| layout-ncol: 2
#| out-width: "45%"
r1 <- residuals(heifers_lm)
hist(r1)
qqnorm(r1); qqline(r1)

```

## Assumptions for Antibiotics Data {.smaller}

### Python code 

```{python py-normality}
#| out-width: "45%"
f, axs = plt.subplots(1, 2, figsize=(8,4))
tmp = plt.subplot(121)
heifers_lm.resid.hist();
tmp = plt.subplot(122)
sm.qqplot(heifers_lm.resid, line="q", ax=tmp);
```

## Comparing specific groups  {.smaller}

1. Compute the estimate of the difference between the two means:
$$
\overline{Y_{i_1}} - \overline{Y_{i_2}}
$$
2. Compute the standard error of the above estimator:
$$
\sqrt{MS_W \left( \frac{1}{n_{i_1}} + \frac{1}{n_{i_2}} \right) }
$$
3. Compute the $100(1- \alpha)%$ confidence interval as:
$$
\overline{Y_{i_1}} - \overline{Y_{i_2}} \pm 
t_{n-k, \alpha/2}  \times
\sqrt{MS_W \left( \frac{1}{n_{i_1}} + \frac{1}{n_{i_2}} \right) }
$$

## Enrofloxacin vs. Control

### R code 

```{r r-pairwise}
# R 
summary_out <- anova(heifers_lm)
est_coef <- coef(heifers_lm)
est1  <- unname(est_coef[3]) # coefficient for Enrofloxacin
MSW <- summary_out$`Mean Sq`[2]
df <- summary_out$Df[2]
q1 <- qt(0.025, df, 0, lower.tail = FALSE)

lower_ci <- est1 - q1*sqrt(MSW * (1/6 + 1/6))
upper_ci <- est1 + q1*sqrt(MSW * (1/6 + 1/6))
cat("The 95% CI for the diff. between Enrofloxacin and Control is (",
    format(lower_ci, digits = 3), ",", 
    format(upper_ci, digits = 3), ").", sep="")
```

## Enrofloxacin vs. Control

### Python code

```{python py-pairwise}
# Python
est1  = heifers_lm.params.iloc[2] - heifers_lm.params.iloc[1]
MSW = heifers_lm.mse_resid
df = heifers_lm.df_resid
q1 = -stats.t.ppf(0.025, df)

lower_ci = est1 - q1*np.sqrt(MSW * (1/6 + 1/6))
upper_ci = est1 + q1*np.sqrt(MSW * (1/6 + 1/6))
print(f"""The 95% CI for the diff. between Enrofloxacin and control is
({lower_ci:.3f}, {upper_ci:.3f}).""") 
```

## Contrast Estimation {.smaller}

A contrast is defined to be:
$$
L = \sum_{i=1}^k c_i \overline{Y_i}, \text{ where } \sum_{i=1}^k c_i = 0
$$


1. Compute the estimate of the contrast:
$$
L = \sum_{i=1}^k c_i \overline{Y_i}
$$
2. Compute the standard error of the above estimator:
$$
\sqrt{MS_W \sum_{i=1}^k \frac{c_i^2}{n_i} }
$$
3. Compute the $100(1- \alpha)%$ confidence interval as:
$$
L \pm
t_{n-k, \alpha/2}  \times
\sqrt{MS_W \sum_{i=1}^k \frac{c_i^2}{n_i} }
$$

## Contrast in Antibiotics data {.smaller}

### Comparing collection of groups

Let sub-group 1 consist of Ivermectin and Fenbendazole. 
Here is how we can compute a confidence interval for the difference between 
this sub-group, and Enrofloxacin.

## Contrast in Antibiotics data {.smaller}

### R code 

```{r r-contrast-a}
c1 <- c(-1, 0.5, 0.5)
n_vals <- c(6, 6, 6)
L <- sum(c1*est_coef[3:5])

#MSW <- summary_out[[1]]$`Mean Sq`[2]
#df <- summary_out[[1]]$Df[2]
se1 <- sqrt(MSW * sum( c1^2 / n_vals ) )

q1 <- qt(0.025, df, 0, lower.tail = FALSE)

lower_ci <- L - q1*se1
upper_ci <- L + q1*se1
cat("The 95% CI for the diff. between the two groups is (",
    format(lower_ci, digits = 2), ",", 
    format(upper_ci, digits = 2), ").", sep="")
```

## Contrast in Antibiotics data {.smaller}

### R code 

```{r r-contrast-b}
cat("The 95% CI for the diff. between the two groups is (",
    format(lower_ci, digits = 2), ",", format(upper_ci, digits = 2), ").", sep="")
```

## Contrast in Antibiotics data {.smaller}

### Python code 

```{python py-contrast}
c1 = np.array([-1, 0.5, 0.5])
n_vals = np.array([6, 6, 6,])
L = np.sum(c1 * heifers_lm.params.iloc[2:5])

MSW = heifers_lm.mse_resid
df = heifers_lm.df_resid
q1 = -stats.t.ppf(0.025, df)
se1 = np.sqrt(MSW*np.sum(c1**2 / n_vals))

lower_ci = L - q1*se1
upper_ci = L + q1*se1
print(f"The 95% CI for the diff. between the two groups is ({lower_ci:.3f}, {upper_ci:.3f}).") 
```

## Bonferroni

* Suppose we wish to perform $m$ pairwise comparisons, either as a test or 
  by computing confidence intervals. 
* If we wish to maintain the significance level of each test at $\alpha$, then
  we should perform each of the $m$ tests/confidence intervals at $\alpha/m$.


## Tukey HSD

### R code 

```{r r-tukey}
TukeyHSD(aov(heifers_lm), ordered = TRUE)
```

## Tukey HSD

### Python code

```{python py-tukey-1a}
import statsmodels.stats.multicomp as mc

cp = mc.MultiComparison(heifers.org, heifers.type)
tk = cp.tukeyhsd()
```

## Tukey HSD

### Python code

```{python py-tukey-1b}
print(tk)
```

## Kruskal-Wallis Procedure

* The test statistic compares the average ranks in the individual groups.
* The null hypothesis is that all groups follow the same distribution. 

1. Pool the observations over all samples, thus constructing a combined sample of 
   size $N = \sum n_i$. Assign ranks to individual observations, using average rank
   in the case of tied observations. Compute the rank sum $R_i$ for each of the $k$
   samples.
2. If there are no ties, compute the test statistic as 
$$
H = \frac{12}{N(N+1)} \sum_{i=1}^k \frac{R_i^2}{n_i} - 3(N+1)
$$
3. If there *are* ties, compute the test statistic as 
$$
H^* = \frac{H}{1 - \frac{\sum_{j=1}^g (t^3_j - t_j)}{N^3 - N}}
$$

   where $t_j$ refers to the number of observations with the same value in the 
   $j$-th cluster of tied observations and $g$ is the number of tied groups.
   
Under $H_0$, the test statistic follows a $\chi^2$ distribution with $k-1$ 
degrees of freedom.

::: {.callout-important}
This test should only be used if $n_i \ge 5$ for all groups.
:::

## Kruskal-Wallis Test

### R code 

```{r r-kw}
kruskal.test(heifers$org, heifers$type)
```

## Kruskal-Wallis Test

### Python code

```{python py-kw}
out = [x[1] for x in heifers.org.groupby(heifers.type)]
stats.kruskal(*out)
```

## Kruskal-Wallis Test

### SAS output

![](../figs/sas_kruskal_wallis.png){width="60%" fig-align="center"}
