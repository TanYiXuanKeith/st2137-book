{
  "hash": "94f79e80e4539c93378b14750f264984",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"2-sample Hypothesis Tests\"\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n## Introduction\n\nIn this topic, we introduce the routines for a common class of hypothesis tests:\nthe scenario of comparing the location parameter of two groups. This technique\nis commonly used in A/B testing to assess if an intervention has resulted in a\nsignificant difference between two groups.\n\nHypothesis tests are routinely abused in many ways by investigators. Such tests\ntypically require strong assumptions to hold, and can result in false positives\nor negatives. As such, personally, I prefer to use confidence intervals to make\nan assessment of the significance of a result. However, in this topic, we\nintroduce how the $p$-values can be obtained for these tests.\n\n## Procedure for Significance Tests {#sec-sig-test-proc}\n\nAs a recap, here is the general approach for conducting a hypothesis test:\n\n### Step 1: Assumptions\n\nIn this step, we make a note of the assumptions required for the test to be\nvalid. In some tests, this step is carried out at the end of the others, but it\nis still essential to perform. Some tests are very sensitive to the assumptions\n- this is the main reason that the class of robust statistics was invented.\n\n### Step 2: State the hypotheses and significance level\n\nThe purpose of hypothesis testing is to make an inferential statement about the\npopulation from which the data arose. This inferential statement is what we\nrefer to as the hypothesis regarding the population.\n\n::: {.callout-note}\nA hypothesis is a statement about population, usually claiming that a parameter\ntakes a particular numerical value or falls in a certain range of values.\n:::\n\nThe hypotheses will be stated as a pair: The first hypothesis is the null\nhypothesis $H_0$ and the second is the alternative hypothesis $H_1$. Both\nstatements will involve the **population parameter** (not the data summary) of\ninterest. For example, if we have a sample of observations from two groups $A$\nand $B$, and we wish to assess if the mean of the populations is different, the\nhypotheses would be\n\n\\begin{eqnarray*}\nH_0: & \\mu_A = \\mu_B \\\\\nH_1: & \\mu_A \\ne \\mu_B \n\\end{eqnarray*}\n\n$H_0$ is usually a statement that indicates \"no difference\", and $H_1$ is\n*usually* the complement of $H_0$. \n\nAt this stage, it is also crucial to state the significance level of the test.\nThe significance level corresponds to the Type I error of the test - the\nprobability of rejecting $H_0$ when in fact it was true. This level is usually\ndenoted as $\\alpha$, and is usually taken to be 5%, but there is no reason to\nadopt this blindly. Think of the choice of 5% as corresponding to accepting an\nerror rate of 1 in 20 - that's how it was originally decided upon by Fisher.\nWhere possible, the significance level should be chosen to be appropriate for\nthe problem at hand.\n\n::: {.callout-warning}\nIt is important to state the significance level at this stage, because if it is\nchosen *after inspecting the data*, the test is no longer valid. This is because,\nafter knowing the $p$-value, one could always choose the significance level such \nthat it yields the *desired* decision (reject or not).\n:::\n\n### Step 3: Compute the test statistic\n\nThe test statistic is usually a measure of how far the observed data deviates \nfrom the scenario defined by $H_0$. Usually, the larger it is, the more evidence \nwe have against $H_0$.\n\nThe construction of a hypothesis test involves the derivation of the exact or\napproximate distribution of the test statistic under $H_0$. Deviations from the \nassumption could render this distribution incorrect.\n\n### Step 4: Compute the $p$-value\n\nThe $p$-value quantifies the chance of observing such a dataset under $H_0$. The \ndistribution of the test statistic under $H_0$ is used to compute this value between \n0 and 1. A value closer to 0 indicates stronger evidence against $H_0$.\n\n### Step 5: State your conclusion\n\nThis is the binary decision stage - either we reject $H_0$, or we do not reject\n$H_0$. It is conventional to use this terminology (instead of \"accepting $H_1$\")\nsince our $p$-value is obtained with respect to $H_0$.\n\n## Confidence Intervals\n\nConfidence intervals are an alternative method of inference for population parameters.\nInstead of yielding a binary reject/do-not-reject result, they return a confidence \ninterval that contains the plausible values for the population parameter. Many \nconfidence intervals are derived by inverting hypothesis tests, and almost all\nconfidence intervals are of the form \n\n$$\n\\text{Sample estimate}\\; \\pm \\; \\text{margin of error} \n$$\n\nFor instance, if we observe $x_1, \\ldots, x_n$ from a Normal distribution, and\nwish to estimate the mean of the distribution, the 95% confidence interval based\non the the $t$ distribution is\n\n$$\n\\bar{x} \\pm t_{0.025, n-1} \\times \\frac{s}{\\sqrt{n}}\n$$\nwhere \n\n* $s$ is the sample standard deviation, and \n* $t_{0.025, n-1}$ is the 0.025-quantile from the $t$ distribution with $n-1$ degrees\nof freedom.\n\nThe formulas for many confidence intervals rely on asymptotic Normality of the \nestimator. However, this is an assumption that can be overcome with the technique \nof bootstrapping. We shall touch on this in the final topic of our course. \n\nBootstrapping can also be used to sidestep the distributional assumptions in hypothesis\ntests, but I still much prefer confidence intervals to tests because they yield an \ninterval; they provide much more information than a binary outcome.\n\n## Parametric Tests\n\nParametric tests are hypothesis tests that assume some form of distribution for\nthe sample (or population) to follow. An example of such a test is the $t$-test, which\nassumes that the data originate from a Normal distribution. \n\nConversely, nonparametric tests are hypothesis tests that do not assume any form\nof distribution for the sample. It seems we should always use non-parametric\ntests since distributional assumptions would not be violated, right?\nUnfortunately, since nonparametric tests are so general, they do not have a high\ndiscriminative ability - we say that they have low power. In other words, if a\ndataset truly comes from a Normal distribution, using the $t$-test would be able\nto detect smaller differences between the groups better than a non-parametric\ntest.\n\nIn this section, we cover parametric tests for comparing the difference in mean \nbetween **two** groups. \n\n### Independent Samples Test\n\nIn an independent samples $t$-test, observations in one group yield\n*no information* about the observations in the other group. Independent samples can\narise in a few ways:\n\n* In an experimental study, study units could be assigned randomly to different\ntreatments, thus forming the two groups.\n* In an observational study, we could draw a random sample from the population, and\nthen record an explanatory categorical variable on each unit, such as the gender\nor senior-citizen status.\n* In an observational study, we could draw a random sample from a group (say\nsmokers), and then a random sample from another group (say non-smokers). This would\nresult in a situation where the independent 2-sample $t$-test is appropriate.\n\n#### Formal Set-up\n\nFormally speaking, this is how the independent 2-sample t-test works:\n\nSuppose that $X_1,X_2,\\ldots,X_{n_1}$ are independent observations from group 1,\nand $Y_1, \\ldots Y_{n_2}$ are independent observations from group 2. It is assumed \nthat \n\n\\begin{eqnarray}\nX_i &\\sim& N(\\mu_1,\\, \\sigma^2),\\; i=1,\\ldots,n_1 \\\\\nY_j &\\sim& N(\\mu_2,\\, \\sigma^2),\\; j=1,\\ldots,n_2\n\\end{eqnarray}\n\nThe null and alternative hypotheses would be \n\n\\begin{eqnarray*}\nH_0: & \\mu_1 = \\mu_2 \\\\\nH_1: & \\mu_1 \\ne \\mu_2 \\\\\n\\end{eqnarray*}\n\nThe test statistic for this test is:\n\n$$\nT_1 = \\frac{(\\bar{X} - \\bar{Y}) - 0 }{s_p\\sqrt{1/n_1 + 1/n_2} }\n$$\nwhere \n$$\ns^2_p = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1) s_2^2}{n_1 + n_2 -2 }\n$$\n\nUnder $H_0$, the test statistic $T_1 \\sim t_{n_1 + n_2 -2}$. When we use a software\nto apply the test above, it will typically also return a confidence interval,\ncomputed as\n\n$$\n(\\bar{X} - \\bar{Y}) \\pm t_{n_1 + n_2 -2, 1 - \\alpha/2} \\times s_p\\sqrt{1/n_1 + 1/n_2}\n$$\n\n::: {style=\"background-color: #D5D1D1; padding: 20px\" #exm-abalone-1}\n\n### Abalone Measurements\n\nThe dataset on abalone measurements from the [UCI machine learning\nrepository](https://archive.ics.uci.edu/dataset/1/abalone) contains measurements\nof physical characteristics, along with the gender status. We derive a sample of\n50 measurements of male and female abalone records for use here. Our goal is \nto study if there is a significant difference between the viscera weight[^1] between\nmales and females. The derived dataset can be found on Canvas.\n\n[^1]: Viscera is the gut weight after bleeding out the abalone (in grams).\n\n::: {.panel-tabset}\n\n#### R code \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nabl <- read.csv(\"data/abalone_sub.csv\")\nx <- abl$viscera[abl$gender == \"M\"]\ny <- abl$viscera[abl$gender == \"F\"]\n\nt.test(x, y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  x and y\nt = 0.91008, df = 98, p-value = 0.365\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.02336287  0.06294287\nsample estimates:\nmean of x mean of y \n  0.30220   0.28241 \n```\n\n\n:::\n:::\n\n\n\n\n#### Python code\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport statsmodels.api as sm\n\nabl = pd.read_csv(\"data/abalone_sub.csv\")\n#abl.head()\n#abalone_df.describe()\n\nx = abl.viscera[abl.gender == \"F\"]\ny = abl.viscera[abl.gender == \"M\"]\n\nt_out = stats.ttest_ind(y, x)\nci_95 = t_out.confidence_interval()\n\nprint(f\"\"\"\n* The p-value for the test is {t_out.pvalue:.3f}. \n* The actual value of the test statistic is {t_out.statistic:.3f}.\n* The upper and lower limits of the CI are ({ci_95[0]:.3f}, {ci_95[1]:.3f}).\n\"\"\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n* The p-value for the test is 0.365. \n* The actual value of the test statistic is 0.910.\n* The upper and lower limits of the CI are (-0.023, 0.063).\n```\n\n\n:::\n:::\n\n\n\n\n#### SAS Output \n\nWhen we run the independent samples t-test on SAS, we should observe the following \noutput @fig-sas-abalone-001.\n\n::: {layout-ncol=1}\n![SAS Abalone, Independent](figs/sas_abalone_ind_ttest-001.png){#fig-sas-abalone-001 fig-align=\"center\" out-width=60%}\n:::\n\n:::\n\nTo assess the normality assumption, we make histograms and qq-plots.\n\n::: {.callout-note}\nOnly the R code is shown here.\n:::\n\n\n\n\n::: {.cell layout=\"[[1],[1,1]]\" layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lattice)\nhistogram(~viscera | gender, data=abl, type=\"count\")\n```\n\n::: {.cell-output-display}\n![Histograms](07-2_sample_tests_files/figure-pdf/r-abalone-2-1.pdf){fig-align='center' width=70%}\n:::\n\n```{.r .cell-code}\nqqnorm(y, main=\"Female Abalones\");  qqline(y)\n```\n\n::: {.cell-output-display}\n![QQ-plot for females](07-2_sample_tests_files/figure-pdf/r-abalone-2-2.pdf){fig-align='center' width=70%}\n:::\n\n```{.r .cell-code}\nqqnorm(x, main=\"Male Abalones\");  qqline(x)\n```\n\n::: {.cell-output-display}\n![QQ-plot for males](07-2_sample_tests_files/figure-pdf/r-abalone-2-3.pdf){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\nWe also need to assess if the variances are equal. While there are many\nhypothesis tests specifically for assessing if variances are equal (e.g. Levene,\nBartlett), in our class, I advocate a simple rule of thumb. If the larger s.d is\nmore than twice the smaller one, than we should not use the equal variance form\nof the test. This rule of thumb is widely used in practice (see @sec-web-ref).\n\n::: {.panel-tabset}\n\n\n#### R code \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naggregate(viscera ~ gender, data=abl, sd)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  gender   viscera\n1      F 0.1087070\n2      M 0.1087461\n```\n\n\n:::\n:::\n\n\n\n\n#### Python code\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nabl.groupby('gender').describe()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       viscera                                                            \n         count     mean       std    min       25%    50%       75%    max\ngender                                                                    \nF         50.0  0.28241  0.108707  0.095  0.201250  0.275  0.365125  0.575\nM         50.0  0.30220  0.108746  0.040  0.253125  0.310  0.348750  0.638\n```\n\n\n:::\n:::\n\n\n\n:::\n\n\nWe would conclude that there is no significant difference between the mean \nviscera weight of males and females.\n:::\n\n<br>\n\nApart from qq-plots, it is worthwhile to touch on additional methods that are \nused to assess how much a dataset deviates from Normality. \n\n### More on Assessing Normality\n\n#### Skewness \n\nThe Normal distribution is symmetric about it's mean. Hence if we observe asymmetry \nin our histogram, we might suspect deviation from Normality. To quantify this \nasymmetry, we use *skewness*. As we can see from @fig-skew, a histogram with a \nlong tail on the right (left) is referred to as right-skewed (corr. left-skewed).\n\n![Right/Non/Left-Skewed histograms](figs/summ_data-05.png){#fig-skew fig-align=\"center\"}\n\nOne method of estimating the skewness of a distribution from data is:\n\n$$\ng_1 = \\frac{\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^3}{[\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2 ]^{3/2}}\n$$\nThis is the method-of-moments estimator for the distribution skewness parameter. A value\nclose to 0 indicates low skewness (i.e. high symmetry). Positive values correspond to \nright-skew and negative values to left-skew.\n\n#### Kurtosis \n\nKurtosis measures the thickness of the tails of a distribution. Large kurtosis \nimplies that the tails are \"fatter\" than those of a Normal, whil small, negative \nvalues indicate that the tails are \"thinner\" than those of a Normal.\n\nThe method of moments estimator is \n\n$$\ng_2 = \\frac{\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^4}{[\\frac{1}{n}\\sum_{i=1}^n (x_i - \\bar{x})^2 ]^2} - 3\n$$\n\n#### Hypothesis tests for Normality\n\nThe Shapiro-Wilk test and the Kolmogorov-Smirnov test are formal hypothesis\ntests with the following hypotheses:\n\n\\begin{eqnarray*}\nH_0: & \\text{ Data follows a Normal distribution} \\\\\nH_1: & \\text{ Data does not follow a Normal distribution} \n\\end{eqnarray*}\n\nYou can read more about them in the references, but take note that applying\nmultiple tests leads to a higher Type I error. Moreover, a large small sample\nsize will almost always reject $H_0$ because small deviations are being classed\nas significant. I advocate a more graphical approach in assessing Normality,\nespecially since the solution to Non-normality (the bootstrap) is readily\naccessible today.\n\n::: {style=\"background-color: #D5D1D1; padding: 20px\" #exm-abalone-norm}\n\n### Abalone Measurements\n\nLet us apply the above computations to the abalone measurements.\n\n::: {.panel-tabset}\n\n#### R code \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DescTools)\naggregate(viscera ~ gender, data=abl, Skew, method=1)\n##   gender   viscera\n## 1      F 0.4060918\n## 2      M 0.2482997\n\naggregate(viscera ~ gender, data=abl, Kurt, method=1)\n##   gender    viscera\n## 1      F -0.2431501\n## 2      M  1.1660593\n\n# Shapiro-Wilk Test only for males:\nshapiro.test(x)\n## \n## \tShapiro-Wilk normality test\n## \n## data:  x\n## W = 0.96779, p-value = 0.1878\n```\n:::\n\n\n\n\n#### Python code\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nabl.groupby(\"gender\").skew()\n##          viscera\n## gender          \n## F       0.418761\n## M       0.256046\n\nfor i,df in abl.groupby('gender'):\n    print(f\"{df.gender.iloc[0]}: {df.viscera.kurt():.4f}\")\n## F: -0.1390\n## M: 1.4220\n    \nstats.shapiro(y)\n## ShapiroResult(statistic=np.float64(0.9677872659314101), pvalue=np.float64(0.1878490793650714))\n```\n:::\n\n\n\n\n#### SAS output \n\n![SAS Normality tests](figs/sas_abalone_normality_tests.png){#fig-sas-norm-001}\n\n:::\n\nAlthough the skewness seems large for the female group, the Normality tests \ndo not reject the null hypothesis (see @fig-sas-norm-001).\n\n:::\n\n\n\n\n{{< pagebreak >}}\n\n\n\n\n\n\n### Paired Sample Test\n\nThe data in a paired sample test also arises from two groups, but the two groups \nare not independent. A very common scenario that gives rise to this test is when \nthe same subject receives both treatments. His/her measurement under each treatment \ngives rise to a measurement in each group. However, the measurements are no longer \nindependent.\n\n::: {style=\"background-color: #D5D1D1; padding: 20px\" #exm-paired-1}\n\n### Reaction time of drivers\n\nConsider a study on 32 drivers sampled from a driving school. Each driver is \nput in a simulation of a driving situation, where a target flashes red and  green\nat random periods. Whenever the driver sees red, he/she has to press a brake button.\n\nFor each driver, the study is carried out twice - at one of the repetitions, the\nindividual carries on a phone conversation while at the other, the driver\nlistens to the radio.\n\nEach measurement falls under one of two groups - \"phone\" or \"radio\", but the measurements\nfor driver $i$ are clearly related. Some people might just have a slower/faster baseline \nreaction time!\n\nThis is a situation where a paired sample test is appropriate, not an independent \nsample test.\n:::\n\n#### Formal Set-up\n\nSuppose that we observe $X_1, \\ldots , X_n$ independent observations from group\n1 and $Y_1, \\ldots, Y_n$ independent observations from group 2. However the pair \n$(X_i, Y_i)$ are correlated. It is assumed that\n\n\\begin{eqnarray}\nX_i &\\sim& N(\\mu_1,\\, \\sigma_1^2),\\; i=1,\\ldots,n \\\\\nY_j &\\sim& N(\\mu_2,\\, \\sigma_2^2),\\; j=1,\\ldots,n\n\\end{eqnarray}\n\nWe let $D_i = X_i - Y_i$ for $i=1, \\ldots, n$. It follows that \n$$\nD_i \\sim N(\\mu_1 - \\mu_2,\\; \\sigma^2_1 + \\sigma^2_2 - 2 cov(X_i, Y_i))\n$$\nThe null and alternative hypotheses are stated in terms of the distribution of\n$D_i$:\n\n\\begin{eqnarray*}\nH_0: & \\mu_D = 0 \\\\\nH_1: & \\mu_D \\ne 0\n\\end{eqnarray*}\n\nThe test statistic for this test is:\n\n$$\nT_2 = \\frac{\\bar{D} - 0 }{s / \\sqrt{n} }\n$$\nwhere \n$$\ns^2 = \\frac{\\sum_{i=1}^n (D_i - \\bar{D})^2}{(n - 1)}\n$$\n\nUnder $H-0$, the test statistic $T_2 \\sim t_{n - 1}$. When we use a software\nto apply the test above, it will typically also return a confidence interval,\ncomputed as\n\n$$\n\\bar{D} \\pm t_{n - 1, 1 - \\alpha/2} \\times s / \\sqrt{n}\n$$\n\n::: {style=\"background-color: #D5D1D1; padding: 20px\" #exm-hr-1}\n\n### Heart Rate Before/After Treadmill\n\nThe following dataset comes from the textbook [@rosner2015fundamentals], where \nan individual recorded his heart rate before using a treadmill (baseline) and \n5 minutes after use, for 12 days in 2006. \n\n::: {.panel-tabset}\n\n#### R code \n\nTo run the paired test, we use the same function `t.test` as earlier, but we set the \nargument `paired`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhr_df <- read.csv(\"data/health_promo_hr.csv\")\nbefore <- hr_df$baseline\nafter <- hr_df$after5\nt.test(before, after, paired=TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPaired t-test\n\ndata:  before and after\nt = -21.714, df = 11, p-value = 2.209e-10\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -16.77286 -13.68548\nsample estimates:\nmean difference \n      -15.22917 \n```\n\n\n:::\n:::\n\n\n\n\n#### Python code\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nhr_df = pd.read_csv(\"data/health_promo_hr.csv\")\n#hr_df.head()\n\nstats.ttest_rel(hr_df.baseline, hr_df.after5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTtestResult(statistic=np.float64(-21.71364533004281), pvalue=np.float64(2.208665955512109e-10), df=np.int64(11))\n```\n\n\n:::\n:::\n\n\n\n\n#### SAS Output\n\n![SAS HR Paired t-test](figs/sas_hr_paired_ttest.png)\n\n\n::: \n\nIt is imperative to also make the checks for Normality. If you were to make\nthem, you would realise that the sample size is rather small - it is difficult\nto make the case for Normality here.\n\nA couple of interesting plots from SAS are these:\n\n::: {layout-ncol=2}\n\n![Paired Profiles](figs/sas_hr_paired_profiles.png)\n\n![Agreement](figs/sas_hr_agreement.png)\n\n:::\n\nWhen we inspect the paired plot, we are looking for a similar gradient for each line,\nor at least similar in sign. If instead, we observed a combination of positive \nand negative gradients, then we would be less confident that there is a difference \nin means between the groups.\n\nFor the agreement, if we were to observe a cloud of points centered around the\nmean, with no clear trend to the points, then we would be more inclined to\nbelieve that the mean difference is not 0.\n\n:::\n\n## Non-parametric Tests\n\nIf the distributional assumptions of the $t$-test are not met, we can take action \nin several ways. Historically, one method was to transform the data (if it was \nskewed) to make the histogram symmetric and thus closer to a Normal. But this was \nnot ideal - it did not help in cases where the data was symmetric but had fatter \ntails than the Normal. As time progressed, statisticians invented tools to overcome\nthe distributional assumptions. One sub-field was robust statistics, which keep \nthe assumptions to a minimum, e.g. only requiring the underlying distribution to be \nsymmetric. Another sub-field was the area of non-parametric statistics, where \nalmost **no** distributional assumptions are made about the data.\n\nIn this section, we cover the non-parametric analogues for independent and paired\n2-sample tests.\n\n### Independent Samples Test {#sec-indep-nonpar}\n\nThe non-parametric analogue of the independent 2-sample test is the Wilcoxon Rank\nSum (WRS) test (equivalent to the Mann-Whitney test). \n\n#### Formal Set-up\n\nSuppose that we observe $X_1, \\ldots , X_{n_1}$ independent observations from group\n1 (with distribution $F$) and $Y_1, \\ldots, Y_{n_2}$ independent observations from\ngroup 2 (with distribution $G$). \n\nThe hypotheses associated with this test are:\n\n\\begin{eqnarray*}\nH_0 &: & F = G \\\\\nH_1 &: & F(x) = G(x - \\Delta), \\Delta \\neq 0\n\\end{eqnarray*}\n\nIn other words, the alternative hypothesis is that the distribution of group 1\nis a location shift of the distribution of group 2.\n\nThe WRS test begins by pooling the $n_1 + n_2$ data points and ranking them. The \nsmallest observation is awarded rank 1, and the largest observation is awarded \nrank $n_1 + n_2$, assuming there are no tied values. If there are tied values, \nthe observations with the same value receive an averaged rank.\n\nCompute $R_1$, the sum of the ranks in group 1. If this sum is large, it means \nthat most of the values in group 1 were larger than those in group 2. Note that \nthe average rank in the combined sample is \n$$\n\\frac{n_1 + n_2 + 1}{2}\n$$\n\nUnder $H_0$, the expected rank sum of group 1 is \n$$\nE(R_1) = n_1 \\times  \\frac{n_1 + n_2 + 1}{2}\n$$\nThus the test statistic is a comparison of $R_1$ with the above expected value:\n\n$$\nW_1 = \\begin{cases}\n\\frac{\\left|R_1 - \\frac{n_1(n_1+n_2+1)}{2} \\right| - \\frac{1}{2}}{\\sqrt{n_1n_2(n_1 + n_2 +1)/12}}, & R_1 \\ne \\frac{n_1 (n_1 + n_2 + 1)}{2} \\text{ and no ties} \\\\\n\\frac{\\left|R_1 - \\frac{n_1(n_1+n_2+1)}{2} \\right| - \\frac{1}{2}}{\\sqrt{n_1n_2 \\left( n_1 + n_2 +1 - \\frac{\\sum_{i=1}^g t_i (t_i^2-1)}{(n_1+n_2)(n_1+n_2-1)} \\right) /12}}, & R_1 \\ne \\frac{n_1 (n_1 + n_2 + 1)}{2} \\text{ and ties present} \\\\\n0, & R_1 = \\frac{n_1 (n_1 + n_2 + 1)}{2} \n\\end{cases}\n$$\n\nThe test above should only be used if both $n_1$ and $n_2$ are at least 10, and if \nthe observations (not the ranks) come from an underlying continuous distribution. If these \nassumptions hold, then the test statistic $W_1$ follows a $N(0,1)$ distribution.\n\nJust as in @sec-pair-nonpar, the $g$ refers to the number of groups with ties,\nand $t_i$ refers to the number of tied values in each group.\n\n::: {style=\"background-color: #D5D1D1; padding: 20px\" #exm-abalone-2}\n\n### Abalone Measurements\n\n::: {.panel-tabset}\n\n#### R code \n\nWe can perform the WRS test in R:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox.test(x, y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  x and y\nW = 1415.5, p-value = 0.2553\nalternative hypothesis: true location shift is not equal to 0\n```\n\n\n:::\n:::\n\n\n\n\n#### Python code\n\nAs mentioned, the Mann-Whitney test will return the same $p$-value as the \nWRS test.\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nstats.mannwhitneyu(y, x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMannwhitneyuResult(statistic=np.float64(1415.5), pvalue=np.float64(0.25527909580927854))\n```\n\n\n:::\n:::\n\n\n\n\n#### SAS Output\n\nThe SAS output can be seen in @fig-sas-wrs-001.\n\n![SAS Output, Wilcoxon Rank Sum](figs/sas_abalone_wrs.png){#fig-sas-wrs-001}\n\n:::\n\nSince we know the number of observations in each group to be more than 10, the\napproximation holds. Comparing to the @exm-abalone-1, observe that we have a\nsimilar conclusion.\n\n:::\n\n\n\n\n{{< pagebreak >}}\n\n\n\n\n\n\n### Paired Samples Test {#sec-pair-nonpar}\n\nThe analogue of the paired sample $t$-test is known as the Wilcoxon Sign Test \n(WST).\n\n#### Formal Set-up\n\nAgain, suppose that we observe $X_1, \\ldots , X_n$ observations from group 1 and\n$Y_1, \\ldots, Y_n$ observations from group 2. Groups 1 and 2 are paired (or\ncorrelated) in some way.\n\nOnce again, we compute $D_i = X_i - Y_i$. The null hypothesis is that\n\n\\begin{eqnarray*}\nH_0 &: & \\text{median of $D_i$ is 0.} \\\\\nH_1 &: & \\text{median of $D_i$ is not 0.}\n\\end{eqnarray*}\n\nWe begin by ranking the $|D_i|$. Ignoring pairs for which $D_i = 0$, we rank the \nremaining observations from 1 for the pair with the smallest absolute value, \nup to $n$ for the pair with the largest absolute value (assuming no ties).\n\nWe then compute $R_1$, the sum of ranks for the positive $D_i$. If this sum is \nlarge, we expect that the pairs with $X_i > Y_i$ have a larger difference (in \nabsolute values) than those with $X_i < Y_i$. Under $H_0$, it can be shown that \n\n$$\nE(R_1) = m(m+1)/4\n$$\nwhere $m$ is the number of of non-zero differences.\n\nThus the test statistic is a comparison of $R_1$ with the above expected value:\n\n$$\nW_2 = \\begin{cases}\n\\frac{\\left|R_1 - \\frac{n(n + 1)}{4} \\right| - \\frac{1}{2}}{\\sqrt{n (n+1)(2n + 1)/24}}, & R_1 \\ne \\frac{n(n + 1)}{4} \\text{ and no ties} \\\\\n\\frac{\\left|R_1 - \\frac{n(n+1)}{4} \\right| - \\frac{1}{2}}{\\sqrt{n (n+1)(2n+1)/(24 - \n\\sum_{i=1}^g (t^3_i - t_i) / 48 )}}, & R_1 \\ne \\frac{n (n + 1)}{4} \\text{ and ties present} \\\\\n0, & R_1 = \\frac{n (n + 1)}{4} \n\\end{cases}\n$$\nwhere $g$ denotes the number of tied groups, and $t_i$ refers to the number of \ndifferences with the same absolute value in the $i$-th tied group.\n\nIf the number of non-zero $D_i$'s is at least 16, then the test statistic $W_2$ \nfollows a $N(0,1)$ distribution approximately. \n\n::: {style=\"background-color: #D5D1D1; padding: 20px\" #exm-hr-2}\n\n### Heart Rate Before/After Treadmill\n\n::: {.panel-tabset}\n\n#### R code\n\nWe can perform the Wilcoxon Signed Rank test in R:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox.test(before, after, paired = TRUE, exact = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWilcoxon signed rank test with continuity correction\n\ndata:  before and after\nV = 0, p-value = 0.002507\nalternative hypothesis: true location shift is not equal to 0\n```\n\n\n:::\n:::\n\n\n\n\n#### Python code\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nstats.wilcoxon(hr_df.baseline, hr_df.after5, \n               correction=True, method='approx')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWilcoxonResult(statistic=np.float64(0.0), pvalue=np.float64(0.002506841661528245))\n```\n\n\n:::\n:::\n\n\n\n\n#### SAS Output \n\n![SAS Signed Rank Test](figs/sas_hr_wilcox.png)\n\n:::\n\nIn this problem, we do not have 16 non-zero $D_i$'s. Hence, we should in fact \nbe using the \"exact\" version of the test (R and Python). However, the exact version \nof the test cannot be used when there are ties. \n\nIn cases like this, we can turn to the bootstrap, or we can use a permutation test. We \nshall revisit these in our final topic.\n\n:::\n\n## Summary\n\nWhile the test statistics are shown in detail, we do not need the full details\nfor our class. I should also point out that the definitions of the test\nstatistic in @sec-indep-nonpar and @sec-pair-nonpar were both taken from\n@rosner2015fundamentals. However, take note that different software have\nslightly different implementations, for instance in how they deal with ties. As\nalways, my advice is to read the documentation as much as possible, and then \nto use the output of the tests as a guide to your decision-making (instead of the \nabsolute truth).\n\n## References\n\n### Website References {#sec-web-ref}\n\n1. [UCI full abalone dataset](https://archive.ics.uci.edu/dataset/1/abalone): The \n   dataset in the examples above, starting from @exm-abalone-1, consists of samples \n   from the full dataset.\n2. Inference recap from Penn State:\n   * [Hypothesis testing recap](https://online.stat.psu.edu/statprogram/reviews/statistical-concepts/hypothesis-testing) \n   * [Confidence intervals recap](https://online.stat.psu.edu/statprogram/reviews/statistical-concepts/confidence-intervals)\n4. [Tests for Normality](https://online.stat.psu.edu/stat501/lesson/7/7.5) More information on the Kolmogorov-Smirnov and Shapiro-Wilks Tests for Normality.\n5. [Overview of $t$-tests](https://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/7-t-tests) This page includes the rule of thumb about deciding when to use the \n   equal variance test, and when to use the unequal variances version.\n6. [SAS vs. R/Python](https://stats.stackexchange.com/questions/65875/different-ways-to-calculate-the-test-statistic-for-the-wilcoxon-rank-sum-test) This link provides an explanation why the WRS test statistic for \n  SAS is different from R in @exm-abalone-2.\n",
    "supporting": [
      "07-2_sample_tests_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}